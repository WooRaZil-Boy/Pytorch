{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Settings\n",
    "\n",
    "### 1) Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "learning_rate = 0.0002\n",
    "num_epoch = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data\n",
    "\n",
    "### 1) Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = dset.MNIST(\"./\", train=True, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
    "mnist_test = dset.MNIST(\"./\", train=False, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
    "#MNIST 데이터를 다운로드 받는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Check Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 60000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), 10000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(mnist_train.__getitem__(0)[0].size(), mnist_train.__len__())\n",
    "mnist_test.__getitem__(0)[0].size(), mnist_test.__len__()\n",
    "\n",
    "#mnist_train도 Dataset type이다. 따라서, len, getitem 메서드를 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Set DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=2, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model & Optimizer\n",
    "\n",
    "### 1) CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict #이건 Python collections 임\n",
    "\n",
    "# class Flatten(nn.Module): #Sequential을 사용할 때 Flatten\n",
    "#     def forward(self, x):\n",
    "#         return x.view(x.size()[0], -1) #class를 따로 만들어 view를 해주면 된다.\n",
    "\n",
    "# class CNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CNN, self).__init__()\n",
    "        \n",
    "#         self.model = nn.Sequential(OrderedDict([\n",
    "#             (\"conv1\", nn.Conv2d(1, 16, 5)), #Conv2d 모델 (in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)\n",
    "#             (\"relu1\", nn.ReLU()),\n",
    "#             (\"conv2\", nn.Conv2d(16, 32, 5)),\n",
    "#             (\"relu2\", nn.ReLU()),\n",
    "#             (\"pool1\", nn.MaxPool2d(2, 2)), \n",
    "#             (\"conv3\", nn.Conv2d(32, 64, 5)),\n",
    "#             (\"relu3\", nn.ReLU()),\n",
    "#             (\"pool2\", nn.MaxPool2d(2, 2)), \n",
    "#             (\"flatten\", Flatten()),\n",
    "#             (\"fc1\", nn.Linear(64*3*3, 100)),\n",
    "#             (\"relu4\", nn.ReLU()),\n",
    "#             (\"fc2\", nn.Linear(100, 10)),\n",
    "#         ]))\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         return self.model(x)\n",
    "    \n",
    "    \n",
    "#Conv2d 모델 (in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)\n",
    "#pooling을 지나면, 채널은 그대로이고 사이즈가 준다. 필터의 수 만큼 반복되므로, 필터의 수가 out_channels 이 된다.\n",
    "    \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(1,16,5), # input : 28 * 28 1채널 #output : 24 * 24 16채널 (5 x 5, stride 1이므로 4씩 줄어든다)\n",
    "            #Conv2d : (in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16,32,5), # input : 24 * 24 16채널 #output : 20 * 20 32채널 (5 x 5, stride 1이므로 4씩 줄어든다)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2), # input : 20 * 20 32채널 #output : 10 * 10 32채널 (pooling에선 채널이 그대로 유지된다)\n",
    "            #MaxPool2d : (kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)\n",
    "            #여기서는 2 * 2 크기로 2칸 씩 이동하므로 절반으로 줄어든다.\n",
    "            nn.Conv2d(32,64,5), # input : 10 * 10 32채널 #output : 6 * 6 64채널 (5 x 5, stride 1이므로 4씩 줄어든다)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2) # input : 6 * 6 64채널 #output : 3 * 3 64채널 (pooling에선 채널이 그대로 유지된다)\n",
    "        )\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(64*3*3,100), #마지막으로 pooling 이후 output이 3 * 3 64채널 이었으므로 이를 FC에 넣어준다.\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100,10)\n",
    "        )       \n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.layer(x)\n",
    "        out = out.view(batch_size,-1)\n",
    "        out = self.fc_layer(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "model = CNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Loss func & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3081, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_epoch):\n",
    "    for j,[image,label] in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(image)\n",
    "        loss = loss_func(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if j % 1000 == 0:\n",
    "            print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for image,label in test_loader:\n",
    "    output = model.forward(image)\n",
    "    _,output_index = torch.max(label,1)\n",
    "        \n",
    "    total += label.size(0)\n",
    "    correct += (output_index == label).sum().float()\n",
    "    \n",
    "print(\"Accuracy of Test Data: {}\".format(100*correct/total))\n",
    "\n",
    "##이미지 데이터에 대해서는 CNN이 Linear보다 확연히 좋은 성능을 보여준다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:turienv]",
   "language": "python",
   "name": "conda-env-turienv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
