{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![GAN.png](images/GAN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla GAN with Multi GPUs + Naming Layers using OrderedDict\n",
    "# Code by GunhoChoi\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils as utils\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "import torchvision.utils as v_utils\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hyperparameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Hyperparameters\n",
    "# change num_gpu to the number of gpus you want to use\n",
    "\n",
    "epoch = 100\n",
    "batch_size = 200\n",
    "learning_rate = 0.0002\n",
    "num_gpus = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Data\n",
    "\n",
    "mnist_train = dset.MNIST(\"./\", train=True, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
    "#MNIST 데이터를 다운로드 받는다.\n",
    "\n",
    "# Set Data Loader(input pipeline)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=mnist_train,batch_size=batch_size,shuffle=True,drop_last=True)\n",
    "#Data Loader를 만들어 준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator receives random noise z and create 1x28x28 image\n",
    "# we can name each layer using OrderedDict\n",
    "\n",
    "class Generator(nn.Module): #Generator는 이미지를 생성한다. #Autoencoder의 decoder가 GAN의 Generator에 해당. \n",
    "    #Autoencoder의 decoder에는 원래 latent vector가 있어야 하지만 GAN에서는 random noise에서 생성하는 것이 기본이다.\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Linear(100, 7*7*256) #size가 100인 데이터를 7*7*256로 늘린다.\n",
    "        \n",
    "        self.layer2 = nn.Sequential(OrderedDict([\n",
    "            (\"conv1\", nn.ConvTranspose2d(256, 128, 3, 2, 1, 1)), \n",
    "            (\"relu1\", nn.LeakyReLU()),\n",
    "            (\"bn1\", nn.BatchNorm2d(128)), #일괄 정규화. 성능과 안정성을 향상시킨다. \n",
    "            #Gradient Vanishing / Gradient Exploding를 방지한다.\n",
    "            #배치 정규화는 레이어의 입력 데이터 분포가 치우쳐져 있을 때 평균과 분산을 조정해주는 역할을 한다. \n",
    "            #이는 역전파가 각 레이어에 쉽게 전달되도록 해 학습이 안정적으로 이뤄지도록 돕는 데 중요한 역할을 한다.\n",
    "            #https://shuuki4.wordpress.com/2016/01/13/batch-normalization-%EC%84%A4%EB%AA%85-%EB%B0%8F-%EA%B5%AC%ED%98%84/\n",
    "            (\"conv2\", nn.ConvTranspose2d(128, 64, 3, 1, 1)), \n",
    "            (\"relu2\", nn.LeakyReLU()), #relu와 비슷하지만, -가 되도 0이 아닌 약간의 값을 가진다.\n",
    "            (\"bn2\", nn.BatchNorm2d(64))\n",
    "        ]))\n",
    "        \n",
    "        self.layer3 = nn.Sequential(OrderedDict([\n",
    "            (\"conv3\", nn.ConvTranspose2d(64, 16, 3, 1, 1)), \n",
    "            (\"relu3\", nn.LeakyReLU()),\n",
    "            (\"bn3\", nn.BatchNorm2d(16)),\n",
    "            (\"conv4\", nn.ConvTranspose2d(16, 1, 3, 2, 1, 1)), \n",
    "            (\"relu4\", nn.LeakyReLU())\n",
    "        ]))\n",
    "        \n",
    "    def forward(self, z):\n",
    "        out = self.layer1(z)\n",
    "        out = out.view(batch_size//num_gpus, 256, 7, 7) #size 변환\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator receives 1x28x28 image and returns a float number 0~1\n",
    "# we can name each layer using OrderedDict\n",
    "\n",
    "class Discriminator(nn.Module): #Discriminator는 생성된 이미지를 판별한다.\n",
    "    #Generator가 fake data를 생성하고, real data와 번갈아 가면서 Discriminator에 넣어준다.\n",
    "    #Discriminator는 fake data는 0로, real data는 1로 판별해야 한다.\n",
    "    #즉, Generator는 fake data를 Discriminator가 real로 판단하도록 학습되어야 한다.\n",
    "    #따라서, Discriminator가 모두 올바르게 판단하면 loss는 0. 모두 잘못 판단하면, 무한대가 나온다.\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(OrderedDict([\n",
    "            (\"conv1\", nn.ConvTranspose2d(1, 16, 3, padding=1)), #batch x 16 x 28 x 28\n",
    "            (\"relu1\", nn.LeakyReLU()),\n",
    "            (\"bn1\", nn.BatchNorm2d(16)),\n",
    "            (\"conv2\", nn.ConvTranspose2d(16, 32, 3, padding=1)), #batch x 32 x 28 x 28\n",
    "            (\"relu2\", nn.LeakyReLU()), #relu와 비슷하지만, -가 되도 0이 아닌 약간의 값을 가진다.\n",
    "            (\"bn2\", nn.BatchNorm2d(32)), \n",
    "            (\"max1\", nn.MaxPool2d(2)) #batch x 32 x 14 x 14\n",
    "        ]))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(OrderedDict([\n",
    "            (\"conv3\", nn.ConvTranspose2d(32, 64, 3, padding=1)), #batch x 64 x 14 x 14\n",
    "            (\"relu3\", nn.LeakyReLU()),\n",
    "            (\"bn3\", nn.BatchNorm2d(64)),\n",
    "            (\"max2\", nn.MaxPool2d(2)), #batch x 64 x 7 x 7\n",
    "            (\"conv4\", nn.ConvTranspose2d(64, 128, 3, padding=1)), #batch x 128 x 7 x 7\n",
    "            (\"relu4\", nn.LeakyReLU())\n",
    "        ]))\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128*7*7, 1), \n",
    "            nn.Sigmoid() #최종적으로 0 또는 1의 값을 내야 하므로 sigmoid로 0~1의 값으로 만들어 준다.\n",
    "        )\n",
    "                                    \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(batch_size//num_gpus, -1)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Put instances on Multi-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put class objects on Multiple GPUs using \n",
    "# torch.nn.DataParallel(module, device_ids=None, output_device=None, dim=0)\n",
    "# device_ids: default all devices / output_device: default device 0 \n",
    "# along with .cuda()\n",
    "\n",
    "# generator = nn.DataParallel(Generator()).cuda()\n",
    "# discriminator = nn.DataParallel(Discriminator()).cuda()\n",
    "#DataParallel는 Multi GPU에 모델을 올릴 수 있다.\n",
    "\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Check layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1.weight\n",
      "layer1.bias\n",
      "layer2.conv1.weight\n",
      "layer2.conv1.bias\n",
      "layer2.bn1.weight\n",
      "layer2.bn1.bias\n",
      "layer2.bn1.running_mean\n",
      "layer2.bn1.running_var\n",
      "layer2.bn1.num_batches_tracked\n",
      "layer2.conv2.weight\n",
      "layer2.conv2.bias\n",
      "layer2.bn2.weight\n",
      "layer2.bn2.bias\n",
      "layer2.bn2.running_mean\n",
      "layer2.bn2.running_var\n",
      "layer2.bn2.num_batches_tracked\n",
      "layer3.conv3.weight\n",
      "layer3.conv3.bias\n",
      "layer3.bn3.weight\n",
      "layer3.bn3.bias\n",
      "layer3.bn3.running_mean\n",
      "layer3.bn3.running_var\n",
      "layer3.bn3.num_batches_tracked\n",
      "layer3.conv4.weight\n",
      "layer3.conv4.bias\n"
     ]
    }
   ],
   "source": [
    "# Get parameter list by using class.state_dict().keys()\n",
    "\n",
    "gen_params = generator.state_dict().keys()\n",
    "dis_params = discriminator.state_dict().keys()\n",
    "\n",
    "for i in gen_params:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Set Loss function & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function, optimizers, and labels for training\n",
    "\n",
    "loss_func = nn.BCELoss()\n",
    "#label이 0 또는 1이기 때문에 Binary Cross Entropy loss를 사용한다. \n",
    "gen_optim = torch.optim.Adam(generator.parameters(), lr=learning_rate)\n",
    "dis_optim = torch.optim.Adam(discriminator.parameters(), lr=learning_rate)\n",
    "#model.parameters() 로 업데이트해야 할 모든 변수들을 한 번에 가져와 간단히 구현할 수 있다.\n",
    "#손실에서 lr만큼 움직이고 업데이트 하던 것을 알아서 최적화해서 처리해 준다.\n",
    "#각 파라미터들을 따로 학습해야 하기 때문에 모델의 optim을 따로 정의해 준다.\n",
    "\n",
    "# ones_label = torch.ones(batch_size,1).cuda()\n",
    "# zeros_label = torch.zeros(batch_size,1).cuda()\n",
    "\n",
    "ones_label = torch.ones(batch_size, 1) #정답. real은 1에 가깝게 나와야 한다.\n",
    "zeros_label = torch.zeros(batch_size, 1) #정답. fake는 0에 가깝게 나와야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Restore Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------model not restored--------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model restore if any\n",
    "\n",
    "try:\n",
    "    generator, discriminator = torch.load('./model/vanilla_gan.pkl')\n",
    "    print(\"\\n--------model restored--------\\n\")\n",
    "except:\n",
    "    print(\"\\n--------model not restored--------\\n\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4817a84f0ad5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mgen_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdis_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mones_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#예측한 값과, 정답 # fake classified as real\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m#Generator 입장에서는 생성된 fake data를 Discriminator가 모두 1로 판단해야 하므로, 정답 label은 모두 1인 tensor가 된다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mgen_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#역전파 해준다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mgen_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#변수 업데이트\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/turienv/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/turienv/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "for i in range(epoch):\n",
    "    for j,(image,label) in enumerate(train_loader): #DataLoader에서 batch 만큼씩 가져온다.\n",
    "#         image = image.cuda()\n",
    "        \n",
    "        # Generator\n",
    "        \n",
    "        for k in range(5):\n",
    "#         z = Variable(init.normal(torch.Tensor(batch_size,z_size),mean=0,std=0.1)).cuda()\n",
    "            z = torch.rand(batch_size, 100) #noise 생성\n",
    "            #매번 랜덤한 noise를 생성해서 이미지를 generate한다.\n",
    "            #Autoencoder의 decoder에는 원래 latent vector가 있어야 하지만 GAN에서는 random noise에서 생성하는 것이 기본이다.\n",
    "            gen_optim.zero_grad() #optimiser.step() 으로 업데이트된 그라디언트 값들을 초기화해 줘야 한다.\n",
    "            gen_fake = generator.forward(z) #noise vector를 generator에 넣어주면, fake data가 생성된다.\n",
    "            dis_fake = discriminator.forward(gen_fake) #fake data를 discriminator에 넣어준다.\n",
    "            #0 ~ 1 사이의 값이 나온다.\n",
    "            gen_loss = torch.sum(loss_func(dis_fake, ones_label)) #예측한 값과, 정답 # fake classified as real\n",
    "            #Generator 입장에서는 생성된 fake data를 Discriminator가 모두 1로 판단해야 하므로, 정답 label은 모두 1인 tensor가 된다.\n",
    "            gen_loss.backward(retain_graph=True) #역전파 해준다.\n",
    "            gen_optim.step() #변수 업데이트\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Discriminator\n",
    "        \n",
    "        dis_optim.zero_grad() #optimiser.step() 으로 업데이트된 그라디언트 값들을 초기화해 줘야 한다.\n",
    "        dis_real = discriminator.forward(image) #real data를 discriminator에 넣어준다.\n",
    "        dis_loss = torch.sum(loss_func(dis_fake, zeros_label)) + torch.sum(loss_func(dis_real, ones_label))\n",
    "        #Discriminator 입장에서는 생성된 fake data를 0로 판단하고, real data는 1로 판단해야 한다.\n",
    "        #두 과정의 loss를 더해준다.\n",
    "        dis_loss.backward() #역전파 해준다.\n",
    "        dis_optim.step() #변수 업데이트\n",
    "        \n",
    "    # model save\n",
    "    if i % 5 == 0:\n",
    "        print(gen_loss, dis_loss)\n",
    "\n",
    "        torch.save([generator, discriminator],'./model/vanilla_gan.pkl') #모델 저장\n",
    "\n",
    "    print(\"{}th iteration gen_loss: {} dis_loss: {}\".format(i,gen_loss.data,dis_loss.data))\n",
    "    v_utils.save_image(gen_fake.data[0:20],\"./result/gen_{}_{}.png\".format(i,j), nrow=5)\n",
    "    #이미지 저장\n",
    "\n",
    "#학습이 잘 되면, Discriminator의 결과값은 0.5에 수렴하게 된다. 이는 진짜 인지 아닌지 구별이 불가능한 상태를 의미한다.\n",
    "#하지만, Discriminator가 제대로 학습이 안되서 구별을 못하는 경우에도 0.5에 수렴하게 나올 수 있다.\n",
    "#아직은 따로 결과를 판단하는 metric이 없어 사람이 직접 눈으로 생성된 이미지를 보고 학습이 제대로 되었는지 판단해야 한다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN의 대표적인 문제점은 다음과 같다.\n",
    "\n",
    "- **Mode Collapse** : 서로 다른 노이즈 값들로 generate해도 하나의 mode로 수렴하는 현상. 네트워크가 다양한 실제 이미지 같은 결과를 내기를 기대하는데 그러싸한 이미지만 만들어냄\n",
    "- **Oscillation** : GAN output들이 목표 카테고리가 여러 가지일 경우, 왔다 갔다 하면서 다양한 결과값들을 만들어 내고 하나에 수렴하지 못하는 경우\n",
    "\n",
    "요즘에는 이런 문제를 해결한 DCGAN을 많이 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:turienv]",
   "language": "python",
   "name": "conda-env-turienv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
