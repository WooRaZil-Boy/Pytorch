{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network with 2D Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict #이건 Python collections 임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = 1000\n",
    "num_epochs = 10000\n",
    "\n",
    "x = init.uniform_(torch.Tensor(num_data, 1), -10, 10)\n",
    "y = init.uniform_(torch.Tensor(num_data, 1), -10, 10)\n",
    "z = x**2 + y**2\n",
    "\n",
    "x_noise = init.normal_(torch.FloatTensor(num_data, 1), std=0.5)\n",
    "y_noise = init.normal_(torch.FloatTensor(num_data, 1), std=0.5)\n",
    "z_noise = x_noise**2 + y_noise**2\n",
    "\n",
    "data_noise = torch.cat([x, y, z_noise], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim=2, output_num=1):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(OrderedDict([\n",
    "            (\"fc1\", nn.Linear(input_dim, 20)), #Linear 모델 (in_features, out_features, bias=True)\n",
    "            (\"relu1\", nn.ReLU()),\n",
    "            (\"fc2\", nn.Linear(20, 10)), \n",
    "            (\"relu2\", nn.ReLU()),\n",
    "            (\"fc3\", nn.Linear(10, 5)), \n",
    "            (\"relu3\", nn.ReLU()),\n",
    "            (\"fc4\", nn.Linear(5, 5)), \n",
    "            (\"relu4\", nn.ReLU()),\n",
    "            (\"fc5\", nn.Linear(5, output_num)), \n",
    "        ]))\n",
    "        #Sequential는 컨테이너로 순서대로 추가된다. 여러 개의 레이어를 합쳐 하나의 이름으로 묶을 수 있다.\n",
    "        #OrderedDict를 사용하면, 개별 레이어와 작업의 이름을 지정해 줄 수 있다. 딕셔너리이므로 key가 중복되어선 안된다.\n",
    "        #https://pytorch.org/docs/master/nn.html#torch.nn.Sequential\n",
    "        \n",
    "        #activate function이 없으면, neural network라도 linear하게 결과를 낼 수 밖에 없다.\n",
    "        #여기 예에서는 activate function이 없으면, 2차원 함수라도 1차원으로 선을 그어 판단하게 된다.\n",
    "        #하지만, activate function이 추가되면, 데이터의 분포에 맞춰 곡선으로 그어질 수 있다.\n",
    "        #Relu 없이 학습해보면 loss 차이를 확인해 볼 수 있다.\n",
    "        \n",
    "    def forward(self, x): #x가 Tensor\n",
    "        return self.model(x)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x1 = self.model(x[0])\n",
    "#         x2 = self.model(x[1])\n",
    "#         x = torch.cat((x1, x2), 1)\n",
    "#         return x\n",
    "    \n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, \tloss 0.9987856149673462\n",
      "epoch 1000, \tloss 0.3502397835254669\n",
      "epoch 2000, \tloss 0.34771111607551575\n",
      "epoch 3000, \tloss 0.34680017828941345\n",
      "epoch 4000, \tloss 0.34619948267936707\n",
      "epoch 5000, \tloss 0.3457992970943451\n",
      "epoch 6000, \tloss 0.34551870822906494\n",
      "epoch 7000, \tloss 0.3453119397163391\n",
      "epoch 8000, \tloss 0.345132976770401\n",
      "epoch 9000, \tloss 0.34495919942855835\n"
     ]
    }
   ],
   "source": [
    "l_rate = 0.001\n",
    "criterion = nn.L1Loss() #손실함수\n",
    "optimizer = optim.SGD(model.parameters(), lr=l_rate) #parameters() 메서드로 해당 객체(모델)의 모든 파라미터를 가져온다.\n",
    "\n",
    "input_data = torch.cat([x, y], 1)\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    optimizer.zero_grad() #optimiser.step으로 업데이트된 그라디언트 값들을 초기화해 줘야 한다.\n",
    "    #이 코드가 없으면, 그라디언트 값들이 누적되어서 제대로 학습되지 않는다.\n",
    "    outputs = model.forward(input_data) #학습\n",
    "    loss = criterion(outputs, z_noise) #예측한 값과, 정답\n",
    "    loss.backward() #역전파 해 준다.\n",
    "    optimizer.step() #변수 업데이트\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print(\"epoch {}, \\tloss {}\".format(i, loss)) #1000번 마다 손실 출력\n",
    "        \n",
    "#원래는 Tensor 값인 x, y를 Variable로 변환해서 traininig 해야 했지만, 4.0 부터는 Tensor 그대로 넣어도 된다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:turienv]",
   "language": "python",
   "name": "conda-env-turienv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
