{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Style Transfer using convolutional neural networks using ResNet50\n",
    "# code by GunhoChoi\n",
    "# Referenced documents below\n",
    "# https://discuss.pytorch.org/t/how-to-extract-features-of-an-image-from-a-trained-model/119/3\n",
    "# https://github.com/leongatys/PytorchNeuralStyleTransfer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils as utils\n",
    "import torch.utils.data as data\n",
    "import torchvision.models as models\n",
    "import torchvision.utils as v_utils\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content & style directory\n",
    "\n",
    "content_dir = \"./image/content/Neckarfront_origin.jpg\"\n",
    "style_dir = \"./image/style/monet.jpg\"\n",
    "\n",
    "# hyperparameters\n",
    "\n",
    "content_layer_num = 1\n",
    "image_size = 256\n",
    "epoch = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /Users/geunseong-gai/.torch/models/resnet50-19c8e357.pth\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1\n",
      "bn1\n",
      "relu\n",
      "maxpool\n",
      "layer1\n",
      "layer2\n",
      "layer3\n",
      "layer4\n",
      "avgpool\n",
      "fc\n"
     ]
    }
   ],
   "source": [
    "# import pretrained resnet50 model\n",
    "# check what layers are in the model\n",
    "# if you want to see more specifically, print module\n",
    "\n",
    "resnet = models.resnet50(pretrained=True) #ResNet50을 불러 온다.\n",
    "for name,module in resnet.named_children(): #ResNet50의 구조\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet without fully connected layers\n",
    "# return activations in each layers \n",
    "\n",
    "class Resnet(nn.Module):\n",
    "    #불러온 pre-trained ResNet50은 우리가 사용하려는 구조와 조금 다르다. 따라서 이를 가져와 조금 변형한 모델을 직접 생성한다.\n",
    "    def __init__(self):\n",
    "        super(Resnet, self).__init__()\n",
    "        self.layer0 = nn.Sequential(*list(resnet.children())[0:1]) #conv1\n",
    "        self.layer1 = nn.Sequential(*list(resnet.children())[1:4]) #bn1, relu, maxpool\n",
    "        self.layer2 = nn.Sequential(*list(resnet.children())[4:5]) #layer1\n",
    "        self.layer3 = nn.Sequential(*list(resnet.children())[5:6]) #layer2\n",
    "        self.layer4 = nn.Sequential(*list(resnet.children())[6:7]) #layer3\n",
    "        self.layer5 = nn.Sequential(*list(resnet.children())[7:8]) #layer4\n",
    "        #Resnet의 마지막 avgpool과 fc를 제거한다.\n",
    "\n",
    "    def forward(self,x):\n",
    "        out_0 = self.layer0(x)\n",
    "        out_1 = self.layer1(out_0)\n",
    "        out_2 = self.layer2(out_1)\n",
    "        out_3 = self.layer3(out_2)\n",
    "        out_4 = self.layer4(out_3)\n",
    "        out_5 = self.layer5(out_4)\n",
    "\n",
    "        return out_0, out_1, out_2, out_3, out_4, out_5 #각 레이어의 output을 각각 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read & preprocess image\n",
    "# normalize by subtracting imagenet mean of rgb channels\n",
    "\n",
    "def image_preprocess(img_dir):\n",
    "    img = Image.open(img_dir) #이미지를 불러온다.\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Scale(image_size), #이미지 크기 변환\n",
    "        transforms.CenterCrop(image_size), #중앙에 위치하도록 자른다.\n",
    "        transforms.ToTensor(), #Torch Tensor로 변환한다. 0 ~ 1 사이 값을 가진다.\n",
    "        transforms.Normalize(mean=[0.40760392, 0.45795686, 0.48501961], \n",
    "                             std=[1,1,1]), #이미지 정규화\n",
    "        #ImageNet : 평균 = [0.485, 0.456, 0.406] 및 표준편차 = [0.229, 0.224, 0.225]로 정규화 된 각 채널의 이미지에 대해 학습된 모델\n",
    "    ])\n",
    "    #transforms은 선처리를 위한 함수, transforms.Compose는 선처리를 위한 컨테이너이다.\n",
    "    \n",
    "    img = transform(img).view((-1,3,image_size,image_size)) #이미지를 선처리 해주고, size 변환한다.\n",
    "    return img\n",
    "\n",
    "# image post process\n",
    "# add imagenet mean to normalize the output image\n",
    "# bound the image -1 to 1\n",
    "\n",
    "def image_postprocess(tensor):\n",
    "    transform = transforms.Normalize(mean=[-0.40760392, -0.45795686, -0.48501961], \n",
    "                                     std=[1,1,1]) #다시 원래 대로 정규화해 준다.\n",
    "    #transforms은 선처리를 위한 함수, transforms.Compose는 선처리를 위한 컨테이너이다.\n",
    "    \n",
    "    img = transform(tensor.clone()) #텐서의 값에 변화가 적용되지 않도록 텐서를 복제한다.\n",
    "    img[img>1] = 1    \n",
    "    img[img<0] = 0\n",
    "    img = 2*(img-0.5)\n",
    "    return img #이미지가 -1 에서 1 사이의 값을 가지게 한다.\n",
    "\n",
    "# show image given a tensor as input\n",
    "\n",
    "def imshow(tensor): #이미지 출력\n",
    "    image = tensor.clone().cpu()\n",
    "    image = image.view(3, image_size, image_size)\n",
    "    image = transforms.ToPILImage()(image) #PIL 이미지로 재 변환\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:turienv]",
   "language": "python",
   "name": "conda-env-turienv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
